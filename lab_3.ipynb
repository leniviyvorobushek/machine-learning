{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHw85w8LwrQC",
    "outputId": "da8f0ed1-4c66-4c54-c812-80f9a262cf63"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import functional\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_curve, roc_auc_score, auc, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "MC4a_dZ2M0y0",
    "outputId": "ab330a9f-4741-489e-de23-5dc5c93a543c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002a283a315af96eaea0e28e7163b21b</td>\n",
       "      <td>borzoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>004396df1acd0f1247b740ca2b14616e</td>\n",
       "      <td>shetland_sheepdog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0067dc3eab0b3c3ef0439477624d85d6</td>\n",
       "      <td>walker_hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
       "      <td>maltese_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>006cc3ddb9dc1bd827479569fcdc52dc</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0075dc49dab4024d12fafe67074d8a81</td>\n",
       "      <td>norfolk_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00792e341f3c6eb33663e415d0715370</td>\n",
       "      <td>african_hunting_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>007b5a16db9d9ff9d7ad39982703e429</td>\n",
       "      <td>wire-haired_fox_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>007b8a07882822475a4ce6581e70b1f8</td>\n",
       "      <td>redbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>008887054b18ba3c7601792b6a453cc3</td>\n",
       "      <td>boxer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id                    breed\n",
       "0   000bec180eb18c7604dcecc8fe0dba07              boston_bull\n",
       "1   001513dfcb2ffafc82cccf4d8bbaba97                    dingo\n",
       "2   001cdf01b096e06d78e9e5112d419397                 pekinese\n",
       "3   00214f311d5d2247d5dfe4fe24b2303d                 bluetick\n",
       "4   0021f9ceb3235effd7fcde7f7538ed62         golden_retriever\n",
       "5   002211c81b498ef88e1b40b9abf84e1d       bedlington_terrier\n",
       "6   00290d3e1fdd27226ba27a8ce248ce85       bedlington_terrier\n",
       "7   002a283a315af96eaea0e28e7163b21b                   borzoi\n",
       "8   003df8b8a8b05244b1d920bb6cf451f9                  basenji\n",
       "9   0042188c895a2f14ef64a918ed9c7b64       scottish_deerhound\n",
       "10  004396df1acd0f1247b740ca2b14616e        shetland_sheepdog\n",
       "11  0067dc3eab0b3c3ef0439477624d85d6             walker_hound\n",
       "12  00693b8bc2470375cc744a6391d397ec              maltese_dog\n",
       "13  006cc3ddb9dc1bd827479569fcdc52dc                 bluetick\n",
       "14  0075dc49dab4024d12fafe67074d8a81          norfolk_terrier\n",
       "15  00792e341f3c6eb33663e415d0715370      african_hunting_dog\n",
       "16  007b5a16db9d9ff9d7ad39982703e429  wire-haired_fox_terrier\n",
       "17  007b8a07882822475a4ce6581e70b1f8                  redbone\n",
       "18  007ff9a78eba2aebb558afea3a51c469         lakeland_terrier\n",
       "19  008887054b18ba3c7601792b6a453cc3                    boxer"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'dataset_lab3/labels.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ih6jfyZNQKa",
    "outputId": "8d079e49-bbd8-44fc-9dcd-c660b2dd9d27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  10222\n",
       "unique                   120\n",
       "top       scottish_deerhound\n",
       "freq                     126\n",
       "Name: breed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['breed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "yM5YzzIIW4is",
    "outputId": "841f49a1-2ef2-4729-e904-a123f5ffc255"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002a283a315af96eaea0e28e7163b21b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>004396df1acd0f1247b740ca2b14616e</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0067dc3eab0b3c3ef0439477624d85d6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00693b8bc2470375cc744a6391d397ec</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>006cc3ddb9dc1bd827479569fcdc52dc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0075dc49dab4024d12fafe67074d8a81</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00792e341f3c6eb33663e415d0715370</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>007b5a16db9d9ff9d7ad39982703e429</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>007b8a07882822475a4ce6581e70b1f8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007ff9a78eba2aebb558afea3a51c469</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>008887054b18ba3c7601792b6a453cc3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  breed\n",
       "0   000bec180eb18c7604dcecc8fe0dba07      0\n",
       "1   001513dfcb2ffafc82cccf4d8bbaba97      1\n",
       "2   001cdf01b096e06d78e9e5112d419397      2\n",
       "3   00214f311d5d2247d5dfe4fe24b2303d      3\n",
       "4   0021f9ceb3235effd7fcde7f7538ed62      4\n",
       "5   002211c81b498ef88e1b40b9abf84e1d      5\n",
       "6   00290d3e1fdd27226ba27a8ce248ce85      5\n",
       "7   002a283a315af96eaea0e28e7163b21b      6\n",
       "8   003df8b8a8b05244b1d920bb6cf451f9      7\n",
       "9   0042188c895a2f14ef64a918ed9c7b64      8\n",
       "10  004396df1acd0f1247b740ca2b14616e      9\n",
       "11  0067dc3eab0b3c3ef0439477624d85d6     10\n",
       "12  00693b8bc2470375cc744a6391d397ec     11\n",
       "13  006cc3ddb9dc1bd827479569fcdc52dc      3\n",
       "14  0075dc49dab4024d12fafe67074d8a81     12\n",
       "15  00792e341f3c6eb33663e415d0715370     13\n",
       "16  007b5a16db9d9ff9d7ad39982703e429     14\n",
       "17  007b8a07882822475a4ce6581e70b1f8     15\n",
       "18  007ff9a78eba2aebb558afea3a51c469     16\n",
       "19  008887054b18ba3c7601792b6a453cc3     17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['breed'] = pd.factorize(df.breed)[0]\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yGYgXTCxQOMQ"
   },
   "outputs": [],
   "source": [
    "class Dogs(Dataset):\n",
    "\n",
    "    def __init__(self, path, annotation, transform = None, target_transform = None):\n",
    "        self.img_labels = annotation['id']\n",
    "        self.img_class = annotation['breed']\n",
    "        self.data_dir = path\n",
    "        self.img_dir = annotation['id']\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = str(self.data_dir + self.img_dir[idx] + '.jpg')\n",
    "        image = read_image(img_path)\n",
    "        image = functional.to_pil_image(image)\n",
    "        label = self.img_class.loc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PP0SxaE5U6iu"
   },
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "path = 'dataset_lab3/train/'\n",
    "train, test = train_test_split(df, test_size=0.05, random_state=42,shuffle=True, stratify=df['breed'])\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_ds = Dogs(path, train, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=100, shuffle=True, drop_last=True)\n",
    "test_ds = Dogs(path, test, transform)\n",
    "test_dl = DataLoader(test_ds, batch_size=100, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAvwohxLdJWQ",
    "outputId": "ce472bee-bdff-477d-dd83-736ea8376572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступно устройств GPU: 0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "print(f\"Доступно устройств GPU: {device_count}\")\n",
    "\n",
    "for i in range(device_count):\n",
    "    device_name = torch.cuda.get_device_name(i)\n",
    "    print(f\"Устройство {i}: {device_name}\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qHCL4YV_89PC"
   },
   "outputs": [],
   "source": [
    "class Dogs_NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dogs_NN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1)\n",
    "        # 6*222*222\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        # 6*111*111\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5, stride=2, padding=1)\n",
    "        # 12*55*55\n",
    "        self.linear1 = nn.Linear(12*55*55, 1000)\n",
    "        self.linear2 = nn.Linear(1000, 120)\n",
    "        #Сворачиваем до 120\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.conv1(input))\n",
    "        output = self.pool1(output)\n",
    "        output = F.relu(self.conv2(output))\n",
    "        output = output.view(output.size(0), 12*55*55)\n",
    "        output = F.relu(self.linear1(output))\n",
    "        output = self.linear2(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rumXt-b19MvD",
    "outputId": "7f7d8dce-bca5-4526-ed53-1319a649375b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss = 4.7801\n",
      "Valid loss = 4.7503\n",
      "time of epoch: 151.65383052825928\n",
      "Epoch [2/5], Loss = 4.6239\n",
      "Valid loss = 4.7382\n",
      "time of epoch: 137.031259059906\n"
     ]
    }
   ],
   "source": [
    "timing = time.time()\n",
    "my_nn = Dogs_NN().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "num_epochs = 5 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch, labels in train_dl:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        my_nn.train()\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_nn(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss = {loss.item():.4f}')\n",
    "    my_nn.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in test_dl:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = my_nn(batch.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    print(f'Valid loss = {loss.item():.4f}')\n",
    "\n",
    "    train_losses.append(train_loss / len(train_dl))\n",
    "    valid_losses.append(valid_loss / len(test_dl))\n",
    "    print(\"time of epoch:\", time.time() - timing)\n",
    "    timing = time.time()\n",
    "\n",
    "print('Training is finished')\n",
    "\n",
    "torch.save(my_nn.state_dict(), 'Dogs_classifier.pth')\n",
    "combined_list = list(zip(train_losses, valid_losses))\n",
    "losses = pd.DataFrame(combined_list, columns=['train_loss', 'valid_loss'])\n",
    "losses.to_csv('Losses_5_epoch.csv', index=False)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "colors = ['#00DD99', '#9900DD']\n",
    "sns.lineplot(data=losses, palette = colors)\n",
    "plt.grid(ls = ':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dogs_NN_2(torch.nn.Module):\n",
    "    # Изначально 3*224*224\n",
    "    def __init__(self):\n",
    "        super(Dogs_NN_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=1)\n",
    "        # 6*222*222\n",
    "        self.pool1 = nn.MaxPool2d(3, stride=2)\n",
    "        # 6*110*110\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=10, stride=1, padding=1)\n",
    "        # 12*103*103\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=3)\n",
    "        # 12*51*51\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=20, stride=1, padding=1)\n",
    "        # 24*34*34\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=3)\n",
    "\n",
    "        self.linear1 = nn.Linear(24*6*6, 512)\n",
    "        self.linear2 = nn.Linear(512, 120)\n",
    "        #Сворачиваем до 120 (сколько целевых классов)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.conv1(input))\n",
    "        output = self.pool1(output)\n",
    "        output = F.relu(self.conv2(output))\n",
    "        output = self.pool2(output)\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = self.pool3(output)\n",
    "        output = output.view(output.size(0), 24*6*6)\n",
    "        output = F.relu(self.linear1(output))\n",
    "        output = self.linear2(output)\n",
    "\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = time.time()\n",
    "my_nn = Dogs_NN_2().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(my_nn.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "num_epochs = 5 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch, labels in train_dl:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        my_nn.train()\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_nn(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss = {loss.item():.4f}')\n",
    "    my_nn.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in test_dl:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = my_nn(batch.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    print(f'Valid loss = {loss.item():.4f}')\n",
    "\n",
    "    train_losses.append(train_loss / len(train_dl))\n",
    "    valid_losses.append(valid_loss / len(test_dl))\n",
    "    print(\"time of epoch:\", time.time() - timing)\n",
    "    timing = time.time()\n",
    "print('Training is finished')\n",
    "\n",
    "torch.save(my_nn.state_dict(), 'Dogs_classifier_2.pth')\n",
    "combined_list = list(zip(train_losses, valid_losses))\n",
    "losses = pd.DataFrame(combined_list, columns=['train_loss', 'valid_loss'])\n",
    "losses.to_csv('Losses_5_epoch_2.csv', index=False)\n",
    "\n",
    "plt.figure(figsize = (9, 6))\n",
    "colors = ['#00DD99', '#9900DD']\n",
    "sns.lineplot(data=losses, palette = colors)\n",
    "plt.grid(ls = ':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import shufflenet_v2_x0_5\n",
    "\n",
    "model = shufflenet_v2_x0_5(pretrained=True)\n",
    "num_classes = df['breed'].nunique()\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch, labels in train_dl:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss = {loss.item():.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in test_dl:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = model(batch.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    print(f'Valid loss = {loss.item():.4f}')\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_dl))\n",
    "    valid_losses.append(valid_loss / len(test_dl))\n",
    "    \n",
    "print('Training is finished')\n",
    "\n",
    "torch.save(model, 'shufflenet_v2_x0_5_Dogs_classifier.pth')\n",
    "combined_list = list(zip(train_losses, valid_losses))\n",
    "losses = pd.DataFrame(combined_list, columns=['train_loss', 'valid_loss'])\n",
    "losses.to_csv('shufflenet_v2_x0_5_Losses_5_epoch.csv', index=False)\n",
    "\n",
    "f = plt.figure(figsize = (9, 6))\n",
    "colors = ['#00DD99', '#9900DD']\n",
    "sns.lineplot(data=losses, palette = colors)\n",
    "plt.grid(ls = ':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "num_classes = df['breed'].nunique()\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch, labels in train_dl:\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss = {loss.item():.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in test_dl:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = model(batch.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "    print(f'Valid loss = {loss.item():.4f}')\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_dl))\n",
    "    valid_losses.append(valid_loss / len(test_dl))\n",
    "    \n",
    "print('Training is finished')\n",
    "\n",
    "torch.save(model, 'resnet18_Dogs_classifier.pth')\n",
    "combined_list = list(zip(train_losses, valid_losses))\n",
    "losses = pd.DataFrame(combined_list, columns=['train_loss', 'valid_loss'])\n",
    "\n",
    "f = plt.figure(figsize = (9, 6))\n",
    "colors = ['#00DD99', '#9900DD']\n",
    "sns.lineplot(data=losses, palette = colors)\n",
    "plt.grid(ls = ':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dogs_NN()\n",
    "model.load_state_dict(torch.load('Dogs_classifier.pth'))\n",
    "model.eval() \n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "valid_data = Dogs(path, test, transform=transform)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "pred_class = []    \n",
    "with torch.no_grad():\n",
    "        for batch, labels in valid_dataloader:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = model(batch.float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted = predicted.cpu()\n",
    "            pred_class.append(predicted.item())\n",
    "            \n",
    "true_class = test['breed'].tolist()\n",
    "f1_macro = f1_score(true_class, pred_class, average='macro')\n",
    "f1_micro = f1_score(true_class, pred_class, average='micro')\n",
    "f1_weighted = f1_score(true_class, pred_class, average='weighted')\n",
    "print(\"F1 метрика (макро):\", f1_macro)\n",
    "print(\"F1 метрика (микро):\", f1_micro)\n",
    "print(\"F1 метрика (среднее взвешенное):\", f1_weighted)\n",
    "\n",
    "precision, recall, _ , _ = precision_recall_fscore_support(true_class, pred_class)\n",
    "accuracy = accuracy_score(true_class, pred_class)\n",
    "precision_aver = precision.mean()\n",
    "recall_aver = recall.mean()\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Average Precision:', precision_aver)\n",
    "print('Average Recall:', recall_aver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Dogs_NN_2()\n",
    "model.load_state_dict(torch.load('Dogs_classifier_2.pth'))\n",
    "model.eval() \n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "valid_data = Dogs(path, test, transform=transform)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "pred_class = []    \n",
    "with torch.no_grad():\n",
    "        for batch, labels in valid_dataloader:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = model(batch.float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted = predicted.cpu()\n",
    "            pred_class.append(predicted.item())\n",
    "            \n",
    "true_class = test['breed'].tolist()\n",
    "f1_macro = f1_score(true_class, pred_class, average='macro')\n",
    "f1_micro = f1_score(true_class, pred_class, average='micro')\n",
    "f1_weighted = f1_score(true_class, pred_class, average='weighted')\n",
    "print(\"F1 метрика (макро):\", f1_macro)\n",
    "print(\"F1 метрика (микро):\", f1_micro)\n",
    "print(\"F1 метрика (среднее взвешенное):\", f1_weighted)\n",
    "\n",
    "precision, recall, _ , _ = precision_recall_fscore_support(true_class, pred_class)\n",
    "accuracy = accuracy_score(true_class, pred_class)\n",
    "precision_aver = precision.mean()\n",
    "recall_aver = recall.mean()\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Average Precision:', precision_aver)\n",
    "print('Average Recall:', recall_aver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 метрика (макро): 0.4096590479523916\n",
      "F1 метрика (микро): 0.451171875\n",
      "F1 метрика (среднее взвешенное): 0.42152491877451964\n",
      "Accuracy: 0.451171875\n",
      "Average Precision: 0.4405888787138787\n",
      "Average Recall: 0.43652777777777774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\PycharmProjects\\lab_script\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('shufflenet_v2_x0_5_Dogs_classifier.pth')\n",
    "model.eval()\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "valid_data = Dogs(path, test, transform=transform)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "pred_class = []    \n",
    "with torch.no_grad():\n",
    "        for batch, labels in valid_dataloader:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = model(batch.float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted = predicted.cpu()\n",
    "            pred_class.append(predicted.item())\n",
    "\n",
    "\n",
    "true_class = test['breed'].tolist()\n",
    "f1_macro = f1_score(true_class, pred_class, average='macro')\n",
    "f1_micro = f1_score(true_class, pred_class, average='micro')\n",
    "print(\"F1 метрика (макро):\", f1_macro)\n",
    "print(\"F1 метрика (микро):\", f1_micro)\n",
    "f1_weighted = f1_score(true_class, pred_class, average='weighted')\n",
    "print(\"F1 метрика (среднее взвешенное):\", f1_weighted)\n",
    "\n",
    "precision, recall, _ , _ = precision_recall_fscore_support(true_class, pred_class)\n",
    "accuracy = accuracy_score(true_class, pred_class)\n",
    "precision_aver = precision.mean()\n",
    "recall_aver = recall.mean()\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Average Precision:', precision_aver)\n",
    "print('Average Recall:', recall_aver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('resnet18_Dogs_classifier.pth')\n",
    "model.eval()\n",
    "\n",
    "transform = Compose([\n",
    "    Resize((224,224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "valid_data = Dogs(path, test, transform=transform)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "pred_class = []    \n",
    "\n",
    "with torch.no_grad():\n",
    "        for batch, labels in valid_dataloader:\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            outputs = model(batch.float())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted = predicted.cpu()\n",
    "            pred_class.append(predicted.item())\n",
    "\n",
    "true_class = test['breed'].tolist()\n",
    "f1_macro = f1_score(true_class, pred_class, average='macro')\n",
    "f1_micro = f1_score(true_class, pred_class, average='micro')\n",
    "print(\"F1 метрика (макро):\", f1_macro)\n",
    "print(\"F1 метрика (микро):\", f1_micro)\n",
    "f1_weighted = f1_score(true_class, pred_class, average='weighted')\n",
    "print(\"F1 метрика (среднее взвешенное):\", f1_weighted)\n",
    "\n",
    "precision, recall, _ , _ = precision_recall_fscore_support(true_class, pred_class)\n",
    "accuracy = accuracy_score(true_class, pred_class)\n",
    "precision_aver = precision.mean()\n",
    "recall_aver = recall.mean()\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Average Precision:', precision_aver)\n",
    "print('Average Recall:', recall_aver)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
